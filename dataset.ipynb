{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('../..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from estimate.irt_tune.irt_eval import fit_irt\n",
    "from utils.util import irt, get_model_param\n",
    "from utils.data import dataSplit_sample_basedParam\n",
    "import os, warnings, random, json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from estimate.irt_gradient_descent import calculate_ability, calculate_ability_binary, calculate_abilities_df_binary_single, calculate_abilities_df_single\n",
    "from src.problem_assistant import Problem_Assiastant\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 参数设置\n",
    "max_num_ratio = 0.02\n",
    "epochs = 100\n",
    "rand_cnt = 1\n",
    "root_path = 'data'\n",
    "benchmark = 'SEEDBench_IMG'\n",
    "\n",
    "# 获取模型信息\n",
    "info_dict, info_df = get_model_param(os.path.join(root_path,'model_information_new.csv'), return_df=True)\n",
    "\n",
    "# 加载测试模型列表\n",
    "with open(os.path.join(root_path,'test_model_list.json'), 'r') as f:\n",
    "    test_model_list = json.load(f)\n",
    "\n",
    "# 准备所有模型列表\n",
    "all_model_list = []\n",
    "train_model_list = []\n",
    "for key, sub_df in info_dict.items():\n",
    "    if key == 'All':\n",
    "        continue\n",
    "    model_list = sub_df['models'].tolist()\n",
    "    all_model_list += model_list\n",
    "\n",
    "train_model_list = list(set(all_model_list) - set(test_model_list))\n",
    "\n",
    "\n",
    "def process_benchmark(benchmark):\n",
    "    print(f\"\\nProcessing benchmark: {benchmark}\")\n",
    "    \n",
    "    # 原始数据路径\n",
    "    orig_pt = f'model_performance/{benchmark}/{benchmark}.csv'\n",
    "    df = pd.read_csv(orig_pt)\n",
    "    \n",
    "    # 准备数据\n",
    "    train_df = df[['model_sha'] + train_model_list]\n",
    "    test_df = df[['model_sha'] + test_model_list]\n",
    "    full_model_list = list(train_model_list) + list(test_model_list)\n",
    "    full_df = df[['model_sha'] + full_model_list]\n",
    "    \n",
    "    # IRT分析\n",
    "    print(\"Running IRT analysis...\")\n",
    "    all_prob_df, all_model_df = irt(full_df, epochs=epochs)\n",
    "    all_prob_df[['loc_diff', 'scale_diff']] = all_prob_df[['difficulty', 'difficulty_std']]\n",
    "    train_prob_df, train_model_df = irt(train_df, epochs=epochs)\n",
    "    train_prob_df[['loc_diff', 'scale_diff']] = train_prob_df[['difficulty', 'difficulty_std']]\n",
    "    \n",
    "    # 创建问题助手\n",
    "    prob_ast = Problem_Assiastant(df, info_df, train_model_list, problem_difficulty=train_prob_df)\n",
    "    \n",
    "    # 创建文件夹结构\n",
    "    data_folder = os.path.join(root_path, benchmark)\n",
    "    train_folder = os.path.join(data_folder, 'train')\n",
    "    test_folder = os.path.join(data_folder, 'test')\n",
    "    full_folder = os.path.join(data_folder, 'full')\n",
    "    \n",
    "    os.makedirs(full_folder, exist_ok=True)\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "    \n",
    "    # 保存数据\n",
    "    def save_data(folder, **kwargs):\n",
    "        for name, data in kwargs.items():\n",
    "            file_path = os.path.join(folder, f'{name}.json')\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                data.to_json(file_path, orient='records', lines=True)\n",
    "            elif isinstance(data, (list, dict)):\n",
    "                with open(file_path, 'w') as f:\n",
    "                    json.dump(data, f, indent=4)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported data type for {name}: {type(data)}\")\n",
    "    \n",
    "    # 保存 train 数据\n",
    "    save_data(\n",
    "        train_folder,\n",
    "        train_model_list=train_model_list,\n",
    "        train_prob_df=train_prob_df,\n",
    "        train_model_df=train_model_df\n",
    "    )\n",
    "    \n",
    "    # 保存 test 数据\n",
    "    save_data(\n",
    "        test_folder,\n",
    "        test_model_list=test_model_list,\n",
    "        all_prob_df=all_prob_df,\n",
    "        all_model_df=all_model_df\n",
    "    )\n",
    "    \n",
    "    save_data(\n",
    "        full_folder,\n",
    "        all_prob_df=all_prob_df,\n",
    "        all_model_df=all_model_df\n",
    "    )\n",
    "    \n",
    "    # 处理CSV到JSON转换\n",
    "    file_path = os.path.join(full_folder, f'{benchmark}.csv')\n",
    "    output_path = os.path.join(full_folder, f'{benchmark}.json')\n",
    "    \n",
    "    # 复制原始文件\n",
    "    cmd = f'cp {orig_pt} {full_folder}'\n",
    "    os.system(cmd)\n",
    "    \n",
    "    # 处理文件并保存为JSON\n",
    "    def process_file_to_dict(file_path):\n",
    "        result_dict = {}\n",
    "        with open(file_path, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            headers = next(reader)\n",
    "            model_names = headers[1:]\n",
    "            \n",
    "            for model_name in model_names:\n",
    "                result_dict[model_name] = {}\n",
    "            \n",
    "            for row in reader:\n",
    "                model_sha = row[0]\n",
    "                for i, value in enumerate(row[1:]):\n",
    "                    model_name = model_names[i]\n",
    "                    result_dict[model_name][model_sha] = value # int(float(value))\n",
    "        return result_dict\n",
    "    \n",
    "    def save_dict_to_json(result_dict, output_path):\n",
    "        with open(output_path, 'w') as file:\n",
    "            for model_name, model_data in result_dict.items():\n",
    "                json_line = json.dumps({model_name: model_data})\n",
    "                file.write(json_line + '\\n')\n",
    "    \n",
    "    result_dict = process_file_to_dict(file_path)\n",
    "    save_dict_to_json(result_dict, output_path)\n",
    "    print(f\"CSV to JSON conversion completed for {benchmark}\")\n",
    "    \n",
    "    # 计算测试模型能力\n",
    "    results = []\n",
    "    for model_under_test in tqdm(test_model_list, desc=f\"Evaluating models for {benchmark}\"):\n",
    "        random_data, selected_diff = prob_ast.get_random_problem([model_under_test], 1, refresh=True)\n",
    "        model_result_df = calculate_abilities_df_binary_single(selected_diff, random_data)\n",
    "        results.append({\"model_sha\": model_under_test, \"ability\": model_result_df['ability'].iloc[0]})\n",
    "    \n",
    "    with open(f'{test_folder}/test_model_df_fullPb.json', 'w') as f:\n",
    "        for result in results:\n",
    "            json.dump(result, f)\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"Completed processing for benchmark: {benchmark}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_benchmark(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
